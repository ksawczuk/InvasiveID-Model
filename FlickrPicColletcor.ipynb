{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# For http interfaces and APIs\n",
    "import requests\n",
    "from flickrapi import FlickrAPI\n",
    "\n",
    "# For performing regex operations\n",
    "import re\n",
    "# For adding delays so that we don't spam requests\n",
    "import time\n",
    "\n",
    "from progress.bar import Bar\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FilckrAPI Implementation\n",
    "1. Load key and secret for API authentication.\n",
    "2. \n",
    "\n",
    "### FlickrAPI Throughput\n",
    "FlickrAPI need to stay below 3600 queries per hour. In order to be conservative, I've put in a 2s delay between image downloads. \n",
    "It doesn't really matter where the delay goes, the effect will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load key and secret\n",
    "f_key = open('Key.txt', encoding='utf-8')\n",
    "f_secret = open('Secret.txt', encoding='utf-8')\n",
    "KEY = f_key.read()\n",
    "SECRET = f_secret.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIZES = ['url_s', 'url_t', 'url_q', 'url_sq' ]  # in order of preference. I only want thumbnails where possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photos(image_tag):\n",
    "    extras = 'url_q'\n",
    "    flickr = FlickrAPI(KEY, SECRET)\n",
    "    photos = flickr.walk(text=image_tag,  # it will search by image title and image tags\n",
    "                            extras=extras,  # get the urls for each size we want\n",
    "                            privacy_filter=1,  # search only for public photos\n",
    "                            per_page=50,\n",
    "                            sort='relevance')  # we want what we are looking for to appear first\n",
    "    return photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(photo):\n",
    "    for i in range(len('url_q')):  # makes sure the loop is done in the order we want\n",
    "        url = photo.get('url_q')\n",
    "        if url:  # if url is None try with the next size\n",
    "            return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(image_tag, max):\n",
    "    photos = get_photos(image_tag)\n",
    "    counter=0\n",
    "    urls=[]\n",
    "\n",
    "    for photo in photos:\n",
    "        if counter < max:\n",
    "            url = get_url(photo)  # get preffered size url\n",
    "            if url:\n",
    "                urls.append(url)\n",
    "                counter += 1\n",
    "            # if no url for the desired sizes then try with the next photo\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(urls, path, plant):\n",
    "    create_folder(path)  # makes sure path exists\n",
    "    \n",
    "    # Create dictionary of values to keep track of file names / paths, species, class, write success\n",
    "    images_dict = {'filename':[], 'class':[], 'species':[], 'write_success':[]}\n",
    "\n",
    "    for url in urls:\n",
    "        image_name = url.split(\"/\")[-1]\n",
    "        image_path = os.path.join(path, image_name)\n",
    "        if not os.path.isfile(image_path):  # ignore if already downloaded\n",
    "            response=requests.get(url,stream=True)\n",
    "\n",
    "            with open(image_path,'wb') as outfile:\n",
    "                outfile.write(response.content)\n",
    "            images_dict['filename'].append(image_name)\n",
    "            images_dict['class'].append(null_class_dict[plant]) \n",
    "            images_dict['species'].append(plant)\n",
    "        time.sleep(2)\n",
    "    return images_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_plant = 350\n",
    "\n",
    "def download(data_dict):\n",
    "    for key in data_dict:\n",
    "\n",
    "        print('Getting urls for', key)\n",
    "        urls = get_urls(key, images_per_plant)\n",
    "        print('Downloading images for', key)\n",
    "        path = os.path.join('data', key)\n",
    "        images_dict = download_images(urls, path, key)\n",
    "    return images_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare inputs for search terms, labels for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of search terms, scientific name, common name(s) and class.\n",
    "# Heracleum mantegazzianum, giant hogweed class 0\n",
    "# Echium vulgare, blueweed class 1\n",
    "# Ulex europaeus, gorse class 2\n",
    "# 'heracleum mantegazzianum': 0, 'giant hogweed': 0, \n",
    "plants = {'blueweed': 1}\n",
    "\n",
    "# Need a list of class 3 plants, will start with these though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Scientific Name</th>\n",
    "        <th>Common Name</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>allium cernuum</td>\n",
    "        <td>nodding onion</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>amsinckia menziesii var. intermedia</td>\n",
    "        <td>common fiddleneck</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>lysimachia thyrsiflora</td>\n",
    "        <td>tufted loosestrife</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mahonia aquifolium</td>\n",
    "        <td>oregon-grape</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>maianthemum racemosum ssp. amplexicaule</td>\n",
    "        <td>false solomon's-seal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>monotropa uniflora</td>\n",
    "        <td>indian-pipe</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>oplopanax horridus</td>\n",
    "        <td>devils club plant</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>pedicularis contorta var. contorta</td>\n",
    "        <td>coil-beaked lousewort</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>phyllodoce empetriformis</td>\n",
    "        <td>pink mountain-heather</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>potentilla drummondii</td>\n",
    "        <td>drummond's cinquefoil</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>ranunculus acris</td>\n",
    "        <td>meadow buttercup</td>\n",
    "    </tr>\n",
    "</table>   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The null class will be made up of 300 images each of 22 plant species native to BC.\n",
    "# 'allium cernuum':3, 'nodding onion':3, 'amsinckia menziesii var. intermedia':3,\n",
    "#                    'common fiddleneck':3, 'lysimachia thyrsiflora':3, \n",
    "#                    'tufted loosestrife':3, 'mahonia aquifolium':3,\n",
    "#                    'oregon-grape':3, 'maianthemum racemosum ssp. amplexicaule':3,\n",
    "#                    'false solomon\\'s-seal':3, 'monotropa uniflora':3, \n",
    "#                    'indian-pipe':3, 'oplopanax horridus':3, \n",
    "#                    'devils club plant':3, 'pedicularis contorta var. contorta':3,\n",
    "#                    'coil-beaked lousewort':3, 'phyllodoce empetriformis':3, \n",
    "#                    'pink mountain-heather':3, 'potentilla drummondii':3,\n",
    "#                    'drummond\\'s cinquefoil':3, 'ranunculus acris':3, \n",
    "#                    'meadow buttercup':3\n",
    "null_class_dict = {'tufted loosestrife':3, 'maianthemum racemosum ssp. amplexicaule':3, \n",
    "                   'pedicularis contorta var. contorta':3, 'potentilla drummondii':3,\n",
    "                   'drummond\\'s cinquefoil':3} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting urls for tufted loosestrife\n",
      "Downloading images for tufted loosestrife\n",
      "Getting urls for maianthemum racemosum ssp. amplexicaule\n",
      "Downloading images for maianthemum racemosum ssp. amplexicaule\n",
      "Getting urls for pedicularis contorta var. contorta\n",
      "Downloading images for pedicularis contorta var. contorta\n",
      "Getting urls for potentilla drummondii\n",
      "Downloading images for potentilla drummondii\n",
      "Getting urls for drummond's cinquefoil\n",
      "Downloading images for drummond's cinquefoil\n"
     ]
    }
   ],
   "source": [
    "images_dict = download(null_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file to save to\n",
    "images_dict_pkl = open('data/images-pickle_file2', 'wb')\n",
    " \n",
    "# write the images dictionary to the file\n",
    "pickle.dump(images_dict, images_dict_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Data\n",
    "\n",
    "Because of the Internal Server 500 errors when getting the URLs for the positive classes images, I will need to create my label dataframe and save to csv from the local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_names = ['blueweed', 'echium_vulgare', 'giant_hogweed', 'gorse', 'heracleum_mantegazzianum', 'ulex_europaeus']\n",
    "image_names = []\n",
    "image_dict = {}\n",
    "for i, dir in enumerate(dir_names):\n",
    "    image_names.append(glob.glob(f'/home/ksawczuk/python-repo/InvasiveId/data/{dir_names[i]}/*.jpg'))\n",
    "    image_dict.update({dir_names[i]:image_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
