{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some standard packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "# Importing tf tools\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, MaxPooling2D, Activation, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ksawczuk/python-repo/InvasiveId'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the local directory structure.\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['giant hogweed', 'blueweed', 'gorse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "Although I've added a decent number of images to my project, I still consider the dataset to be fairly small for an image classification project.\n",
    "<br>\n",
    "Therefore, I've decided to employ the ImageDataGenerator which allows for batches of images to be transformed and augmented in line and fed to the model one at a time.\n",
    "This will assist with memory management and should allow the maximum amount of info regarding each image to end up in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Keras ImageDataGenerator for memory efficiency and preprocessing ease\n",
    "# This process replaces the method of obtaining our data via DataLoader.ipynb\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4862 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                    'data/final_BC_images/train',\n",
    "                                                    target_size=(32, 32),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True,\n",
    "                                                    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1215 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                                                        'data/final_BC_images/train/',\n",
    "                                                        target_size=(32, 32,),\n",
    "                                                        color_mode='rgb',\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=False,\n",
    "                                                        subset='validation'\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1632 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                  'data/final_BC_images/test/',\n",
    "                                                  target_size=(32, 32),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step size = 151 \n",
      "Validation step size = 37 \n",
      "Test step size = 51\n"
     ]
    }
   ],
   "source": [
    "# Saving the number of stepsizes for the training, validation and test sets \n",
    "train_stepsize = train_generator.samples//train_generator.batch_size \n",
    "\n",
    "valid_stepsize = validation_generator.samples//validation_generator.batch_size \n",
    "\n",
    "test_stepsize = test_generator.samples//test_generator.batch_size \n",
    "\n",
    "# Sanity check \n",
    "print(f'Training step size = {train_stepsize} \\nValidation step size = {valid_stepsize} \\nTest step size = {test_stepsize}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1.  Import the pretrained VGG16 network, do not include the top layers\n",
    "pretrained_VGG = VGG16(weights='imagenet', include_top=False, pooling='max', input_shape=(64, 64, 3))\n",
    "\n",
    "# 2.  Setting all layers to not trainable so weights wont be tweaked\n",
    "for layer in pretrained_VGG.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "# Display VGG16 architecture\n",
    "pretrained_VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the VGG16 NN model \n",
    "weeds_VGG = Sequential()\n",
    "\n",
    "# Add the pretrained layers \n",
    "weeds_VGG.add(pretrained_VGG) \n",
    "\n",
    "# Add fully-connected dense layers -- plus a dropout layer to help prevent overfitting\n",
    "weeds_VGG.add(Dense(256, activation='relu'))\n",
    "weeds_VGG.add(Dropout(0.5))\n",
    "weeds_VGG.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Adding our activation \n",
    "weeds_VGG.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Initiate early stop based on validation accuracy\n",
    "ES = EarlyStopping(monitor='val_acc', patience=5, mode='auto', min_delta=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Istantiating Adam optimizer with a learning rate of 0.0001 and saving to variable 'optim'\n",
    "optim = Adam(lr=0.0001)\n",
    "\n",
    "# Compiling the CNN model \n",
    "weeds_VGG.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Summary \n",
    "weeds_VGG.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### VGG16 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the model to the training data\n",
    "history_VGG_2nd = weeds_VGG.fit_generator(generator=train_generator,\n",
    "                                steps_per_epoch=train_stepsize,\n",
    "                                epochs=50,\n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=valid_stepsize,\n",
    "                                callbacks=[ES])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### VGG16 Results (lr = 0.01)\n",
    "* Learning Rate set to 0.01\n",
    "* named 1st for 1st iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Getting bestmodel's predictions (as probabilities) on the test set \n",
    "test_probas_VGG_1st = weeds_VGG.predict_generator(test_generator, steps=test_stepsize)\n",
    "\n",
    "# Setting the model's class prediction as the class that received the highest probability for each image\n",
    "test_predictions_VGG_1st = test_probas_VGG_1st.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Getting the true class labels for the test set\n",
    "test_true_VGG = test_generator.classes\n",
    "\n",
    "# Sanity check \n",
    "test_true_VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Look at what our model predicted\n",
    "test_predictions_VGG_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Displaying the classification report for the test set\n",
    "print('Classification Report\\n \\n', classification_report(test_true_VGG, test_predictions_VGG_1st, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get a confusion matrix \n",
    "test_matrix_VGG_1st = pd.DataFrame(confusion_matrix(test_true_VGG, test_predictions_VGG_1st), \n",
    "                           columns=['Predicted ' + cat_name for cat_name in categories], \n",
    "                           index=['True ' + cat_name for cat_name in categories])\n",
    "\n",
    "# Plotting as a heatmap \n",
    "plt.figure()\n",
    "sns.heatmap(test_matrix_VGG_1st, cmap='Blues', annot=True, fmt='g')\n",
    "plt.title('VGG 16: Normalized Confusion Matrix: Test Data(lr=0.01)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Loss and Accuracy per Epoch \n",
    "learning rate set to 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(0,18,1), history_VGG_1st.history['loss'], label = 'train loss lr:0.01', c = 'b')\n",
    "plt.plot(range(0,18,1), history_VGG_1st.history['val_loss'], label = 'val loss lr:0.01', c = 'r')\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['loss'], label = 'val loss lr:0.0001', c = 'g')\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['val_loss'], label = 'val loss lr:0.0001', c = 'y')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(0,18,1), history_VGG_1st.history['acc'], label = 'train acc lr:0.01', c = 'b')\n",
    "plt.plot(range(0,18,1), history_VGG_1st.history['val_acc'], label = 'val acc lr:0.01', c = 'r')\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['acc'], label = 'train acc lr:0.0001', c = 'g')\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['val_acc'], label = 'val acc lr:0.0001', c = 'y')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy (lr=0.01)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### VGG16 Results (lr = 0.0001)\n",
    "Learning Rate set to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Getting bestmodel's predictions (as probabilities) on the test set \n",
    "test_probas_VGG_2nd = weeds_VGG.predict_generator(test_generator, steps=test_stepsize)\n",
    "\n",
    "# Setting the model's class prediction as the class that received the highest probability for each image\n",
    "test_predictions_VGG_2nd = test_probas_VGG_2nd.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Look at what our model predicted\n",
    "test_predictions_VGG_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Displaying the classification report for the test set\n",
    "print('Classification Report\\n \\n', classification_report(test_true_VGG, test_predictions_VGG_2nd, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get a confusion matrix \n",
    "test_matrix_VGG_2nd = pd.DataFrame(confusion_matrix(test_true_VGG, test_predictions_VGG_2nd), \n",
    "                           columns=['Predicted ' + cat_name for cat_name in categories], \n",
    "                           index=['True ' + cat_name for cat_name in categories])\n",
    "\n",
    "# Plotting as a heatmap \n",
    "plt.figure()\n",
    "sns.heatmap(test_matrix_VGG_2nd, cmap='Blues', annot=True, fmt='g')\n",
    "plt.title('VGG 16: Normalized Confusion Matrix: Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Loss and Accuracy per Epoch \n",
    "learning rate set to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['loss'], label = 'train loss', c = 'b')\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['val_loss'], label = 'val loss', c = 'r')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss (lr=0.0001)')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['acc'], label = 'train acc', c = 'b')\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['val_acc'], label = 'val acc', c = 'r')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy (lr=0.0001)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1.  Import the pretrained VGG16 network, do not include the top layers\n",
    "pretrained_VGG = VGG16(weights='imagenet', include_top=False, pooling='max', input_shape=(32, 32, 3))\n",
    "\n",
    "# 2.  Setting all layers to not trainable so weights wont be tweaked\n",
    "for layer in pretrained_VGG.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "# Display VGG16 architecture\n",
    "pretrained_VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the VGG16 NN model \n",
    "VGG = Sequential()\n",
    "\n",
    "# Add the pretrained layers \n",
    "VGG.add(pretrained_VGG) \n",
    "\n",
    "# Add fully-connected dense layers -- plus a dropout layer to help prevent overfitting\n",
    "# 1st perform batch normalizaiton:\n",
    "\n",
    "VGG.add(Dense(256, activation='relu'))\n",
    "VGG.add(BatchNormalization())\n",
    "VGG.add(Dense(512, activation='relu'))\n",
    "VGG.add(Dropout(0.5))\n",
    "VGG.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Adding our activation \n",
    "VGG.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate early stop based on validation accuracy\n",
    "ES = EarlyStopping(monitor='val_loss', patience=5, mode='auto', min_delta=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 15,110,723\n",
      "Trainable params: 395,523\n",
      "Non-trainable params: 14,715,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Istantiating Adam optimizer with a learning rate of 0.0001 and saving to variable 'optim'\n",
    "optim = Adam(lr=0.0001)\n",
    "\n",
    "# Compiling the CNN model \n",
    "VGG.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Summary \n",
    "VGG.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-8bdb2c944341>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "151/151 [==============================] - 95s 626ms/step - loss: 0.7540 - acc: 0.6798 - val_loss: 0.5329 - val_acc: 0.7872\n",
      "Epoch 2/50\n",
      "151/151 [==============================] - 96s 634ms/step - loss: 0.5551 - acc: 0.7799 - val_loss: 0.4735 - val_acc: 0.8201\n",
      "Epoch 3/50\n",
      "151/151 [==============================] - 99s 656ms/step - loss: 0.5124 - acc: 0.7998 - val_loss: 0.4306 - val_acc: 0.8235\n",
      "Epoch 4/50\n",
      "151/151 [==============================] - 99s 655ms/step - loss: 0.4783 - acc: 0.8124 - val_loss: 0.3888 - val_acc: 0.8522\n",
      "Epoch 5/50\n",
      "151/151 [==============================] - 99s 653ms/step - loss: 0.4643 - acc: 0.8153 - val_loss: 0.3978 - val_acc: 0.8454\n",
      "Epoch 6/50\n",
      "151/151 [==============================] - 99s 657ms/step - loss: 0.4514 - acc: 0.8224 - val_loss: 0.4028 - val_acc: 0.8454\n",
      "Epoch 7/50\n",
      "151/151 [==============================] - 98s 652ms/step - loss: 0.4313 - acc: 0.8313 - val_loss: 0.4014 - val_acc: 0.8471\n",
      "Epoch 8/50\n",
      "151/151 [==============================] - 99s 655ms/step - loss: 0.4239 - acc: 0.8329 - val_loss: 0.3738 - val_acc: 0.8556\n",
      "Epoch 9/50\n",
      "151/151 [==============================] - 102s 673ms/step - loss: 0.4257 - acc: 0.8364 - val_loss: 0.3936 - val_acc: 0.8497\n",
      "Epoch 10/50\n",
      "151/151 [==============================] - 99s 658ms/step - loss: 0.4034 - acc: 0.8404 - val_loss: 0.3827 - val_acc: 0.8497\n",
      "Epoch 11/50\n",
      "151/151 [==============================] - 99s 654ms/step - loss: 0.3971 - acc: 0.8458 - val_loss: 0.3689 - val_acc: 0.8581\n",
      "Epoch 12/50\n",
      "151/151 [==============================] - 98s 652ms/step - loss: 0.3993 - acc: 0.8422 - val_loss: 0.3783 - val_acc: 0.8581\n",
      "Epoch 13/50\n",
      "151/151 [==============================] - 98s 651ms/step - loss: 0.3956 - acc: 0.8441 - val_loss: 0.3826 - val_acc: 0.8564\n",
      "Epoch 14/50\n",
      "151/151 [==============================] - 99s 655ms/step - loss: 0.3858 - acc: 0.8507 - val_loss: 0.3691 - val_acc: 0.8581\n",
      "Epoch 15/50\n",
      "151/151 [==============================] - 99s 655ms/step - loss: 0.3808 - acc: 0.8505 - val_loss: 0.3597 - val_acc: 0.8699\n",
      "Epoch 16/50\n",
      "151/151 [==============================] - 99s 654ms/step - loss: 0.3740 - acc: 0.8557 - val_loss: 0.3821 - val_acc: 0.8539\n",
      "Epoch 17/50\n",
      "151/151 [==============================] - 98s 651ms/step - loss: 0.3865 - acc: 0.8493 - val_loss: 0.3715 - val_acc: 0.8666\n",
      "Epoch 18/50\n",
      "151/151 [==============================] - 99s 654ms/step - loss: 0.3659 - acc: 0.8536 - val_loss: 0.3488 - val_acc: 0.8649\n",
      "Epoch 19/50\n",
      "151/151 [==============================] - 99s 659ms/step - loss: 0.3784 - acc: 0.8538 - val_loss: 0.3637 - val_acc: 0.8682\n",
      "Epoch 20/50\n",
      "151/151 [==============================] - 100s 659ms/step - loss: 0.3642 - acc: 0.8561 - val_loss: 0.3651 - val_acc: 0.8657\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model to the training data\n",
    "history_VGG = VGG.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=train_stepsize,\n",
    "                        epochs=50,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=valid_stepsize,\n",
    "                        callbacks=[ES])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning\n",
    "Unfreeze all the layers of the pretrained model, recompile without rebuilding to ensure normalization values aren't lost.<br>\n",
    "Retrain on the data to provide better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.training.Model at 0x7fee8424d4f0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fee841fd670>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fee841fdca0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fee841a1790>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7fee841a9430>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fee8416cf10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fee84178cd0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_VGG.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 15,110,723\n",
      "Trainable params: 15,110,211\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Istantiating Adam again optimizer with a learning rate of 0.0001 and saving to variable 'optim'\n",
    "optim = Adam(lr=0.00001) \n",
    "\n",
    "# Compiling the CNN model \n",
    "VGG.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Summary \n",
    "VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 341s 2s/step - loss: 0.3582 - acc: 0.8673 - val_loss: 0.4181 - val_acc: 0.8590\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 355s 2s/step - loss: 0.3155 - acc: 0.8783 - val_loss: 0.3003 - val_acc: 0.8986\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 356s 2s/step - loss: 0.3013 - acc: 0.8863 - val_loss: 0.2916 - val_acc: 0.8885\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 355s 2s/step - loss: 0.2758 - acc: 0.8967 - val_loss: 0.2865 - val_acc: 0.8978\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 355s 2s/step - loss: 0.2640 - acc: 0.9037 - val_loss: 0.2728 - val_acc: 0.9012\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 355s 2s/step - loss: 0.2460 - acc: 0.9093 - val_loss: 0.2655 - val_acc: 0.9012\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 357s 2s/step - loss: 0.2438 - acc: 0.9066 - val_loss: 0.2913 - val_acc: 0.9046\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 355s 2s/step - loss: 0.2358 - acc: 0.9168 - val_loss: 0.2738 - val_acc: 0.8927\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 356s 2s/step - loss: 0.2225 - acc: 0.9168 - val_loss: 0.3795 - val_acc: 0.8826\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 356s 2s/step - loss: 0.2258 - acc: 0.9186 - val_loss: 0.2822 - val_acc: 0.8919\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model to the training data\n",
    "history_VGG_fine_tune = VGG.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=train_stepsize,\n",
    "                        epochs=10,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=valid_stepsize,\n",
    "                        callbacks=[ES])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 Results (lr = 0.0001)\n",
    "Learning Rate set to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Getting bestmodel's predictions (as probabilities) on the test set \n",
    "test_probas_VGG_2nd = weeds_VGG.predict_generator(test_generator, steps=test_stepsize)\n",
    "\n",
    "# Setting the model's class prediction as the class that received the highest probability for each image\n",
    "test_predictions_VGG_2nd = test_probas_VGG_2nd.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what our model predicted\n",
    "test_predictions_VGG_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the classification report for the test set\n",
    "print('Classification Report\\n \\n', classification_report(test_true_VGG, test_predictions_VGG_2nd, target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a confusion matrix \n",
    "test_matrix_VGG_2nd = pd.DataFrame(confusion_matrix(test_true_VGG, test_predictions_VGG_2nd), \n",
    "                           columns=['Predicted ' + cat_name for cat_name in categories], \n",
    "                           index=['True ' + cat_name for cat_name in categories])\n",
    "\n",
    "# Plotting as a heatmap \n",
    "plt.figure()\n",
    "sns.heatmap(test_matrix_VGG_2nd, cmap='Blues', annot=True, fmt='g')\n",
    "plt.title('VGG 16: Normalized Confusion Matrix: Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Accuracy per Epoch \n",
    "learning rate set to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['loss'], label = 'train loss', c = 'b')\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['val_loss'], label = 'val loss', c = 'r')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss (lr=0.0001)')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['acc'], label = 'train acc', c = 'b')\n",
    "plt.plot(range(0,20,1), history_VGG_2nd.history['val_acc'], label = 'val acc', c = 'r')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy (lr=0.0001)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
